# AI-Powered Data Science Agent

## Overview

The AI-Powered Data Science Agent is an intelligent autonomous system designed to perform complete end-to-end data science workflows through natural language interaction. This agent leverages Google Gemini 2.5 Flash for advanced reasoning and function calling capabilities, combined with a comprehensive suite of over 82 specialized machine learning tools.

The system enables users to upload datasets in CSV or Parquet format and describe their analytical objectives in plain English. The agent autonomously handles the entire pipeline including data profiling, quality assessment, cleaning, feature engineering, model training, hyperparameter optimization, cross-validation, and comprehensive reporting generation.

Key capabilities include intelligent intent classification, session memory for contextual awareness, error recovery mechanisms, and a modern React-based web interface for seamless user interaction.

[![React](https://img.shields.io/badge/React-19-61DAFB?logo=react)](https://reactjs.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.109-009688?logo=fastapi)](https://fastapi.tiangolo.com/)
[![Gemini](https://img.shields.io/badge/Gemini-2.5_Flash-4285F4?logo=google)](https://ai.google.dev/)
[![Python](https://img.shields.io/badge/Python-3.10+-3776AB?logo=python)](https://python.org/)

---

## Key Features

### Autonomous AI Agent System

The core orchestration engine integrates Google Gemini 2.5 Flash with over 82 specialized machine learning tools organized across multiple categories:

- **Data Profiling Tools**: Generate comprehensive statistical summaries, distribution analysis, correlation matrices, data quality reports, and automated anomaly detection
- **Data Cleaning Tools**: Handle missing values with intelligent imputation strategies (mean, median, mode, forward/backward fill, KNN), outlier detection and treatment using IQR and Z-score methods, duplicate removal, and data type conversions
- **Feature Engineering Tools**: Create time-based features (hour, day, month, year, cyclical encodings), polynomial features, interaction terms, statistical aggregations, lag features, rolling window statistics, and domain-specific transformations
- **Model Training Tools**: Support for multiple algorithm families including linear models (Ridge, Lasso, ElasticNet), tree-based models (Random Forest, Gradient Boosting), and advanced gradient boosting frameworks (XGBoost, LightGBM, CatBoost)
- **Visualization Tools**: Generate interactive Plotly visualizations, Matplotlib static plots, correlation heatmaps, distribution plots, scatter matrices, feature importance charts, and residual analysis plots

The intelligent orchestration system uses function calling capabilities to dynamically select and execute appropriate tools based on user intent. The agent maintains session memory for contextual awareness across conversation turns, enabling multi-turn dialogues where previous actions and results inform subsequent decisions.

Smart intent detection automatically classifies incoming requests into categories such as full ML pipeline execution, exploratory data analysis, data cleaning only, visualization generation, or multi-intent tasks requiring combined workflows.

Error recovery mechanisms include automatic retry logic with corrected parameters, file existence validation before tool execution, recovery guidance displaying the last successful file state, and loop detection to prevent infinite retry cycles.

### Modern Web Interface

The frontend is built with React 19 and TypeScript 5.8, featuring a modern glassmorphism design aesthetic with smooth animations powered by Framer Motion. Key interface components include:

- **Landing Page**: Geometric hero section with animated background paths, key capabilities showcase, problem-solution presentation, process flow visualization, and technology stack display
- **Chat Interface**: Real-time message streaming, file upload support for CSV and Parquet formats, markdown rendering for formatted responses with code syntax highlighting, loading states with animated indicators, and error handling with user-friendly messages
- **Report Viewer**: In-application modal viewer for HTML reports generated by YData Profiling, Sweetviz, and custom dashboard tools. Full-screen modal with professional styling, iframe embedding for report content, and download capabilities
- **Session Management**: Maintains conversation history across browser sessions, allows users to review previous analyses, and provides context for follow-up questions

### Complete Machine Learning Pipeline

The agent executes a comprehensive end-to-end pipeline:

1. **Data Profiling and Assessment**: Automatically generates statistical summaries including descriptive statistics (mean, median, standard deviation, quartiles), distribution analysis with histogram generation, correlation analysis with heatmap visualization, missing value analysis with percentage calculations, data type detection and validation, outlier detection using multiple methods (IQR, Z-score, isolation forest), and cardinality analysis for categorical variables

2. **Data Cleaning and Preprocessing**: Handles missing values with context-aware imputation strategies, removes or treats outliers based on statistical thresholds, performs data type conversions and casting, removes duplicate records, handles inconsistent formatting in categorical variables, and validates data integrity constraints

3. Quick Start Guide

### Prerequisites

Before beginning the installation, ensure your system meets the following requirements:

- **Python**: Version 3.10 or higher with pip package manager
- **Node.js**: V Steps

**Step 1: Clone the Repository**

Clone the repository from GitHub and navigate to the project directory:

```bash
git clone https://github.com/Pulastya-B/DevSprint-Data-Science-Agent.git
cd DevSprint-Data-Science-Agent
```

**Step 2: Configure Environment Variables**

Create a `.env` file in the root directory with the following configuration:

```bash
# LLM Provider Configuration
LLM_PROVIDER=gemini

# Google Gemini API Key (required)
GOOGLE_API_KEY=your_api_key_here

# Model Configuration
GEMINI_MODEL=gemini-2.5-flash

# Cache Configuration
CACHE_DB_PATH=./cache_db/cache.db
CACHE_TTL_SECONDS=86400

# Output and Data Directories
OUTPUT_DIR=./outputs
DATA_DIR=./data
```

Replace `your_api_key_here` with your actual Google Gemini API key obtained from https://ai.google.dev/

**Step 3: Install Python Dependencies**

Install all required Python packages using pip:

```bash
pip install -r requirements.txt
```

ThiUsage Guide

### Web Interface Workflow

**Step 1: Access the Application**

Open your web browser and navigate to http://localhost:8080. You will see the landing page with an overview of the agent's capabilities.

**Step 2: Launch the Chat Interface**

Click the "Launch Agent" button to access the interactive chat interface.

**Step 3: Upload Your Dataset**

Click the file upload button (paperclip icon) and select your dataset file. Supported formats:
- CSV files (.csv) with any delimiter (comma, tab, semicolon, etc.)
- Parquet files (.parquet) for high-performance columnar storage

The agent will automatically detect the file format and load the data using appropriate parsers.

**Step 4: Describe Your Task**

Type your request in natural language in the chat input box. The agent understands various types of requests and will automatically determine the appropriate workflow.

**Step 5: Review Results**

The agent will execute the requested workflow and display results in the chat interface. For analyses that generate HTML reports (such as YData Profiling or Sweetviz), a "View Report" button will appear. Click this button to open the report in a full-screen modal viewer.

### Example Queries and Use Cases

**Data Profiling and Exploration:**
```
"Generate a comprehensive profile report on this dataset"
"Show me the statistical summary and distribution of all variables"
"Analyze data quality issues including missing values and outliers"
"Create a correlation matrix and identify highly correlated features"
```

**Data Cleaning:**
```
"Clean the missing values using median imputation for numeric columns"
"Handle outliers in the dataset using IQR method"
"Remove duplicate records and fix data type inconsistencies"
"Drop columns with more than 50% missing values"
```

**Predictive Modeling:**
```
"Train a model to predict the target column 'price' using all features"
"Build a classification model for the 'churn' column"
"Compare multiple regression algorithms and select the best one"
"Train an XGBoost model with default hyperparameters"
```

**Feature Engineering:**
```
"Extract time-based features from the datetime column"
"Create interaction terms between numeric features"
"Apply target encoding for high-cardinality categorical variables"
"Generate polynomial features of degree 2"
```

**Model Optimization:**
```
"Perform hyperparameter tuning on the trained model using Optuna"
"Run 5-fold cross-validation to evaluate model performance"
"Optimize the XGBoost model for better accuracy"
```

**Visualization:**
```
"Generate a correlation heatmap for numeric features"
"Create distribution plots for all numeric columns"
"Show feature importance for the trained model"
"Generate interactive Plotly visualizations"
```

**End-to-End Pipeline:**
```
"Profile the data, clean it, engineer features, and train the best model"
"Perform complete analysis and predict the target column 'sales'"
"Do everything needed to build a production-ready model
.\start.ps1
```

**For Linux/macOS:**
```bash
chmod +x start.sh
./start.sh
```

The startup script will:
1. Technology Stack

### Frontend Technologies

- **React 19.2.3**: Latest version of React with improved concurrent rendering, automatic batching, and enhanced hooks for building performant user interfaces
- **TypeScript 5.8.2**: Provides static type checking, enhanced IDE support, and improved code maintainability with advanced type inference
- **Vite 6.2.0**: Next-generation frontend build tool offering instant server start, lightning-fast hot module replacement (HMR), and optimized production builds
- **Tailwind CSS 3.4.1**: Utility-first CSS framework enabling rapid UI development with pre-built classes and responsive design utilities
- **Framer Motion 12.23.26**: Production-ready animation library for React with declarative animations, gestures, and smooth transitions
- **React Markdown 9.0.1**: Markdown rendering component supporting GitHub-flavored markdown, code syntax highlighting, and custom renderers
- **Lucide React**: Icon library providing consistent, customizable SVG icons for the user interface

### Backend Technologies

- **FastAPI 0.109+**: Modern, high-performance Python web framework with automatic OpenAPI documentation, async/await support, and built-in request validation
- **Google Gemini 2.5 Flash**: Large language model with advanced reasoning capabilities, function calling support, and high token limits for agent orchestration
- **Polars 0.20+**: High-performance DataFrame library written in Rust, offering 10-100x speed improvements over pandas for large datasets
- **Scikit-learn 1.3+**: Comprehensive machine learning library providing classical algorithms for classification, regression, clustering, and preprocessing
- **XGBoost 2.0+**: Optimized gradient boosting framework with parallel tree construction, regularization, and efficient handling of sparse data
- **LightGBM 4.1+**: Gradient boosting framework by Microsoft with leaf-wise tree growth, categorical feature support, and memory efficiency
- **CatBoost 1.2+**: Gradient boosting library by Yandex with native categorical feature handling, GPU support, and symmetric tree structure
- **Optuna 3.5+**: Hyperparameter optimization framework with Bayesian optimization, pruning strategies, and distributed optimization support
- **YData Profiling 4.6+**: Automated exploratory data analysis tool generating comprehensive HTML reports with statistical summaries and data quality insights
- **Plotly 5.18+**: Interactive visualization library creating web-based charts with zooming, panning, and hover tooltips
- **Matplotlib 3.8+**: Fundamental plotting library for Python offering publication-quality static visualizations
- **Pydantic 2.5+**: Data validation library using Python type annotations for request/response models

### Data Processing and Storage

- **Polars**: Primary dataframe library for all data manipulation operations
- **Pandas 2.1+**: Secondary support for compatibility with legacy tools and libraries
- **SQLite**: Embedded database for caching query results and session management
- **Python-dotenv**: Environment variable management from .env files

### Development and Deployment

- **Docker**: Containerization platform with multi-stage builds for optimized image size and consistent deployment
- **Uvicorn**: Lightning-fast ASGI server for running FastAPI applications
- **Git**: Version control system for code management and collaboration
**4. Install frontend dependencies**
```bash
cd FRRONTEEEND
npm install
npm run build
cd ..
```

**5. Run the application**

**Windows:**
```powershell
.\start.ps1
```

**Linux/Mac:**
```bash
chmod +x start.sh
./start.sh
```

The application will be available at **http://localhost:8080**

---

## ğŸ“– Usage

### Web Interface

1. **Navigate to http://localhost:8080**
2. **Click "Launch Agent"** from the landing page
3. **Upload your dataset** (CSV or Parquet format)
4. **Type your request** in natural language:
   - "Generate a comprehensive report on this dataset"
   - "Train a model to predict [target_column]"
   - "Clean the data and show me visualizations"
   - "Perform feature engineering and train the best model"
5. **View results** in the chat and click "View Report" buttons to see detailed HTML reports

### Example Queries

```
ğŸ“Š "Profile this dataset and tell me about data quality issues"

ğŸ§¹ "Clean the missing values and handle outliers"

ğŸ¯ "Train a model to predict house prices with target column 'price'"

ğŸ“ˆ "Generate a correlation heatmap and feature importance plot"

ğŸ”§ "Create time-based features and perform hyperparameter tuning"

ğŸ“‹ "Generate a comprehensive YData profiling report"
```

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    React Frontend (Port 8080)                â”‚
â”‚  Landing Page â”‚ Chat Interface â”‚ Report Viewer               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FastAPI Backend (Python 3.10+)                  â”‚
â”‚  /chat â”‚ /run â”‚ /outputs â”‚ /api/health                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           DataScienceCopilot Orchestrator                    â”‚
â”‚  â€¢ Gemini 2.5 Flash Integration                             â”‚
â”‚  â€¢ 82+ Specialized Tools                                     â”‚
â”‚  â€¢ Session Memory & Context                                  â”‚
â”‚  â€¢ Intelligent Intent Detection                              â”‚
â”‚  â€¢ Error Recovery & Loop Prevention                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Tool Categories                          â”‚
â”‚  Profiling â”‚ Cleaning â”‚ Feature Engineering â”‚ ML Training   â”‚
â”‚  Visualization â”‚ EDA Reports â”‚ Data Wrangling               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

##  Tech Stack

### Frontend
- **React 19** - Modern UI library
- **TypeScript 5.8** - Type-safe development
- **Vite 6** - Lightning-fast build tool
- **Tailwind CSS** - Utility-first styling
- **Framer Motion** - Smooth animations
- **React Markdown** - Formatted responses

### Backend
- **FastAPI** - High-performance Python web framework
- **Google Gemini 2.5 Flash** - LLM for agent orchestration
- **Polars** - Fast dataframe library (10-100x faster than pandas)
- **Scikit-learn** - Classical ML algorithms
- **XGBoost / LightGBM / CatBoost** - Gradient boosting frameworks
- **Optuna** - Hyperparameter optimization
- **YData Profiling** - Automated EDA reports
- **Plotly / Matplotlib** - Interactive visualizations

### DevOps
- **Docker** - Containerization with multi-stage builds
- **Python-dotenv** - Environment variable management
- **SQLite** - Caching layer for performance

---

## ğŸ³ Docker Deployment

**Build and run with Docker:**

```bash
docker build -t ds-agent .
docker run -p 8080:8080 --env-file .env ds-agent
```

**Or use the deployment script:**

```bash
.\build-and-deploy.ps1  # Windows
./build-and-deploy.sh   # Linux/Mac
```

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ FRRONTEEEND/              # React frontend
â”‚   â”œâ”€â”€ components/           # UI components
â”‚   â”‚   â”œâ”€â”€ ChatInterface.tsx # Main chat interface
â”‚   â”‚   â”œâ”€â”€ HeroGeometric.tsx # Landing page hero
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ dist/                 # Built frontend
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ src/                      # Python backend
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ app.py           # FastAPI application
â”‚   â”œâ”€â”€ orchestrator.py      # Agent orchestrator
â”‚   â”œâ”€â”€ session_memory.py    # Session management
â”‚   â”œâ”€â”€ tools/               # 82+ ML tools
â”‚   â”‚   â”œâ”€â”€ data_profiling.py
â”‚   â”‚   â”œâ”€â”€ data_cleaning.py
â”‚   â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â”‚   â”œâ”€â”€ model_training.py
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ utils/               # Helper utilities
â”‚
â”œâ”€â”€ Dockerfile               # Multi-stage Docker build
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ start.ps1 / start.sh    # Quick start scripts
â””â”€â”€ README.md               # This file
```

---

## ğŸ”‘ Environment Variables

Create a `.env` file in the root directory:

```bash
# LLM Provider Configuration
LLM_PROVIDER=gemini

# API Keys
GOOGLE_API_KEY=your_gemini_api_key_here

# Model Configuration
GEMINI_MODEL=gemini-2.5-flash

# Cache Configuration
CACHE_DB_PATH=./cache_db/cache.db
CACHE_TTL_SECONDS=86400

# Output Configuration
OUTPUT_DIR=./outputs
DATA_DIR=./data
```

---

## ğŸ¯ Features in Detail

### Intelligent Intent Detection
The agent automatically classifies your request and applies the appropriate workflow:
- **Full ML Pipeline** - Complete end-to-end workflow with training
- **Exploratory Analysis** - Data profiling and visualization only
- **Cleaning Only** - Data quality improvements without modeling
- **Visualization Only** - Generate plots and dashboards
- **Multi-Intent** - Combine multiple tasks intelligently

### Session Memory
The agent remembers context across messages:
```
You: "Train a model on this dataset"
Agent: [Trains XGBoost model with RÂ² = 0.85]

You: "Now try hyperparameter tuning"
Agent: [Automatically uses previous model and dataset]

You: "Cross-validate it"
Agent: [Applies CV to tuned model from context]
```

### Error Recovery
- Automatic retry with corrected parameters
- File existence validation before execution
- Recovery guidance showing last successful file
- Loop detection to prevent infinite retries

### Report Viewing
- Click "View Report" buttons to see HTML reports in-app
- Full-screen modal with professional styling
- Supports YData Profiling, Sweetviz, and custom dashboards

---

## ğŸ“Š Example Workflow

**Upload:** `earthquake_data.csv` (175K rows, 22 columns)

**Prompt:** "Train a model to predict earthquake magnitude"

**Agent Actions:**
1. âœ… Profiles dataset (175,947 rows, 22 columns)
2. âœ… Detects data quality issues (11.67% missing, outliers)
3. âœ… Drops high-missing columns (>40% missing)
4. âœ… Imputes remaining missing values with median/mode
5. âœ… Handles outliers with IQR clipping
6. âœ… Extracts time-based features (year, month, hour, cyclical)
7. âœ… Encodes categorical variables
8. âœ… Trains 6 baseline models (XGBoost wins with RÂ² = 0.716)
9. âœ… Performs hyperparameter tuning (RÂ² = 0.743)
10. âœ… Runs 5-fold cross-validation (RMSE = 0.167 Â± 0.0005)
11. âœ… Generates YData profiling report
12. âœ… Creates interactive Plotly dashboard

**Result:** Trained and tuned XGBoost model ready for deployment!

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

---

## ğŸ“„ License

This project is licensed under the MIT License.

---

## ğŸ™ Acknowledgments

- **Google Gemini** for powerful LLM capabilities
- **FastAPI** for excellent async Python framework
- **React** community for amazing UI libraries
- **Polars** for blazing-fast data processing
- **YData Profiling** for comprehensive EDA reports

---

## ğŸ“§ Contact

**Pulastya B**
- GitHub: [@Pulastya-B](https://github.com/Pulastya-B)
- Project: [DevSprint-Data-Science-Agent](https://github.com/Pulastya-B/DevSprint-Data-Science-Agent)

---

<div align="center">

**Built with â¤ï¸ for DevSprint Hackathon**

â­ Star this repo if you find it helpful!

</div>
